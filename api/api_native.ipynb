{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TcmOx48JqtWq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izmeeJoOrkTt"
      },
      "source": [
        "# Run models on Nebius Token Factory (Native)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nebius/token-factory-cookbook/blob/main/api/api_native.ipynb)\n",
        "[![](https://img.shields.io/badge/Powered%20by-Nebius-orange?style=flat&labelColor=darkblue&color=orange)](http://tokenfactory.nebius.com/)\n",
        "\n",
        "This the recommended API.  The API uses OpenAI library.\n",
        "\n",
        "## References and Acknowledgements\n",
        "\n",
        "- [API documentation](https://docs.tokenfactory.nebius.com//inference/quickstart)\n",
        "\n",
        "## Pre requisites\n",
        "\n",
        "- Nebius API key.  Sign up for free at [Token Factory](https://tokenfactory.nebius.com/)\n",
        "- And complete [the setup](https://github.com/nebius/token-factory-cookbook/blob/main/setup-dev-env.md)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNJ-WCDSEy0G"
      },
      "source": [
        "## 1 - Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTElVQApE9I7",
        "outputId": "545945e2-891a-42ef-bd1f-43144ec79e62"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "!pip install -q openai   python-dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xp6woeSsFGo5"
      },
      "source": [
        "## 2 - Load Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFSX16IeFLKa",
        "outputId": "40304ba1-036f-4e79-b836-2b706a9a1bcc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NOT running in Colab\n",
            "âœ… NEBIUS_API_KEY found\n"
          ]
        }
      ],
      "source": [
        "import os, sys\n",
        "\n",
        "## Recommended way of getting configuration\n",
        "if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
        "   print(\"Running in Colab\")\n",
        "   from google.colab import userdata\n",
        "   NEBIUS_API_KEY = userdata.get('NEBIUS_API_KEY')\n",
        "else:\n",
        "   print(\"NOT running in Colab\")\n",
        "\n",
        "   from dotenv import load_dotenv\n",
        "\n",
        "   this_dir = os.path.abspath('')\n",
        "   parent_dir = os.path.dirname(this_dir)\n",
        "   sys.path.append (os.path.abspath (parent_dir))\n",
        "\n",
        "   load_dotenv()\n",
        "   NEBIUS_API_KEY = os.getenv('NEBIUS_API_KEY')\n",
        "\n",
        "\n",
        "## quick hack (not recommended) - you can hardcode the config key here\n",
        "# NEBIUS_API_KEY = \"your_key_here\"\n",
        "\n",
        "if NEBIUS_API_KEY:\n",
        "  print ('âœ… NEBIUS_API_KEY found')\n",
        "  os.environ['NEBIUS_API_KEY'] = NEBIUS_API_KEY\n",
        "else:\n",
        "  raise RuntimeError ('âŒ NEBIUS_API_KEY NOT found')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3vB3EdQGnLX"
      },
      "source": [
        "## 3 - Pick a Model\n",
        "\n",
        "1. Go to **models** tab in [tokenfactory.nebius.com](https://tokenfactory.nebius.com/)\n",
        "2. Copy the model name.  For example **`openai/gpt-oss-20b-Instruct-2507`**\n",
        "\n",
        "![](https://raw.githubusercontent.com/nebius/token-factory-cookbook/main/images/token-factory-1-models.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4 - Run the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8htBO7iH6-e",
        "outputId": "f5280299-a087-4708-c1dc-4c2f5669bf08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----model answer -----\n",
            "The capital of France is Paris.\n",
            "\n",
            "----- full response ----\n",
            "{\n",
            "  \"id\": \"chatcmpl-50f7bcb284ed40cbb45d67225acbb97d\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"message\": {\n",
            "        \"content\": \"The capital of France is Paris.\",\n",
            "        \"refusal\": null,\n",
            "        \"role\": \"assistant\",\n",
            "        \"annotations\": null,\n",
            "        \"audio\": null,\n",
            "        \"function_call\": null,\n",
            "        \"tool_calls\": [],\n",
            "        \"reasoning_content\": null\n",
            "      },\n",
            "      \"stop_reason\": null,\n",
            "      \"token_ids\": null\n",
            "    }\n",
            "  ],\n",
            "  \"created\": 1762232990,\n",
            "  \"model\": \"openai/gpt-oss-20b-Instruct-2507\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"service_tier\": null,\n",
            "  \"system_fingerprint\": null,\n",
            "  \"usage\": {\n",
            "    \"completion_tokens\": 8,\n",
            "    \"prompt_tokens\": 15,\n",
            "    \"total_tokens\": 23,\n",
            "    \"completion_tokens_details\": null,\n",
            "    \"prompt_tokens_details\": null\n",
            "  },\n",
            "  \"prompt_logprobs\": null,\n",
            "  \"prompt_token_ids\": null,\n",
            "  \"kv_transfer_params\": null\n",
            "}\n",
            "---------\n",
            "CPU times: user 235 ms, sys: 62.5 ms, total: 298 ms\n",
            "Wall time: 1.94 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "    base_url=\"https://api.tokenfactory.nebius.com/v1/\",\n",
        "    api_key=NEBIUS_API_KEY,\n",
        ")\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "  model = \"openai/gpt-oss-20b-Instruct-2507\",\n",
        "  messages=[\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"What is the capital of France?\"\n",
        "    }\n",
        "  ],\n",
        "  temperature=0.6\n",
        ")\n",
        "\n",
        "print ('----model answer -----')\n",
        "print (completion.choices[0].message.content)\n",
        "print ('\\n----- full response ----')\n",
        "print(completion.to_json())\n",
        "print ('---------')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5 - Try a Reasoning Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5KlDwxJjhEX",
        "outputId": "0aaeb48f-3efa-4cb1-dc1b-b4758bab81f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "I'm Qwen3, the latest large language model developed by Tongyi Lab! Here's a quick overview of what I can do for you:\n",
            "\n",
            "---\n",
            "\n",
            "### âœ¨ **Key Capabilities**\n",
            "1. **Language Understanding & Generation**  \n",
            "   - Answer questions (e.g., \"Explain quantum computing simply\")  \n",
            "   - Summarize long documents or articles  \n",
            "   - Write stories, emails, scripts, and creative content  \n",
            "   - *Example:* \"Write a 200-word poem about autumn in the style of Shakespeare.\"\n",
            "\n",
            "2. **Code Writing & Debugging**  \n",
            "   - Generate code in **Python, JavaScript, Java, C++, SQL**, and more  \n",
            "   - Fix errors and optimize existing code  \n",
            "   - *Example:* \"Debug this Python function thatâ€™s causing a `KeyError`.\"\n",
            "\n",
            "3. **Multilingual Support**  \n",
            "   - Translate between **100+ languages** (e.g., Chinese â†” English, Spanish â†” French)  \n",
            "   - Understand and respond in your preferred language  \n",
            "   - *Example:* \"Translate this paragraph into Japanese.\"\n",
            "\n",
            "4. **Long-Context Processing**  \n",
            "   - Handle inputs up to **128,000 tokens** (e.g., process a full book or lengthy research paper).\n",
            "\n",
            "5. **Logical Reasoning & Math**  \n",
            "   - Solve puzzles, math problems, and logical sequences  \n",
            "   - *Example:* \"Solve this equation: 3x + 5 = 20.\"\n",
            "\n",
            "6. **Role-Playing & Creative Tasks**  \n",
            "   - Simulate characters or scenarios (e.g., \"Act as a travel guide for Paris\")  \n",
            "   - Generate business plans, marketing copy, or technical documentation.\n",
            "\n",
            "---\n",
            "\n",
            "### ðŸ’¡ **Why It Matters**\n",
            "- **No internet access**: I rely on my training data (up to 2024), so I canâ€™t fetch real-time infoâ€”but Iâ€™m great for *structured* tasks like writing, coding, and analysis.  \n",
            "- **Efficient & Cost-Effective**: Optimized for speed and affordability, whether youâ€™re a developer, student, or business user.\n",
            "\n",
            "---\n",
            "\n",
            "**Try me out!** Ask anything like:  \n",
            "- \"Write a Python script to scrape a website.\"  \n",
            "- \"Explain blockchain to a 10-year-old.\"  \n",
            "- \"Help me draft a resignation email.\"  \n",
            "\n",
            "Let me know what youâ€™d like to tackle! ðŸ˜Š\n",
            "----------\n",
            "CPU times: user 5.25 ms, sys: 2.43 ms, total: 7.68 ms\n",
            "Wall time: 35.1 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "# try another model\n",
        "completion = client.chat.completions.create(\n",
        "  model = \"openai/gpt-oss-20b-Thinking-2507\", # this is a reasoning model\n",
        "  messages=[\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"\"\"What are your capabilities?\"\"\"\n",
        "    }\n",
        "  ],\n",
        "  temperature=0.6\n",
        ")\n",
        "\n",
        "print (completion.choices[0].message.content)\n",
        "print ('----------')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6 - Try Your Queries\n",
        "\n",
        "Go ahead and experiment with your queries.  Here are some to get you started.\n",
        "\n",
        "> Write python code to read a csv file\n",
        "\n",
        "> write a haiku about cats"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "upstream-2-tf-launch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
